{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "841bb3b3-7125-4c05-8b2c-2710537a1a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, Model\n",
    "from tensorflow.keras.layers import Input, Dense, Flatten, Concatenate, Dropout, BatchNormalization, LeakyReLU\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "from tensorflow.keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3a2883e-d396-46f7-8134-8a54cf5bfcbc",
   "metadata": {},
   "source": [
    "### Load Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9a70b95-f488-48e5-a563-0eba85413b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(r\"C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\processed_data\\final_train_data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5115236-3a8a-4d5e-9b26-8ab95a9ef668",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 2066)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e3c3977-a9f1-4052-875c-1c58a5569ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract structured data (already encoded & scaled)\n",
    "# Extract first 18 columns, excluding columns 1, 6, and 7\n",
    "structured_data = data.iloc[:, :18]  # First 18 columns\n",
    "structured_data = structured_data.drop(columns=[data.columns[0], data.columns[5], data.columns[6]])\n",
    "structured_data_scaled = structured_data.values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd3b639-7bc5-47c4-baea-1679e1114663",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0bad21c8-98c8-47b3-8a3f-f70ee6adc9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract image features\n",
    "image_features = data.iloc[:, 18:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1d0adeb8-e50b-4b8d-b4af-5483b76556d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1310, 2048)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "57740ae8-57f0-49e0-b7be-f2ee520f8cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract labels\n",
    "condition_labels = data['Condition'].values  # Binary classification target\n",
    "amount_labels = data['Amount'].values.reshape(-1, 1)  # Regression target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4930818-54eb-40bc-94a7-56668f76783a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n"
     ]
    }
   ],
   "source": [
    "print(np.isnan(image_features).sum(), np.isnan(structured_data_scaled).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c62cce-fac2-404d-a6be-853de84c30c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bd193549-e5ea-4105-8ba9-647f208a5365",
   "metadata": {},
   "source": [
    "### Build Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22d2e40e-efe3-4dd4-8dac-e22037be7de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_input = Input(shape=(image_features.shape[1],), name='image_input')\n",
    "x = Dense(512, kernel_initializer='he_normal', kernel_regularizer=l2(0.00095))(image_input)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(negative_slope=0.1)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "\n",
    "x = Dense(256, kernel_initializer='he_normal', kernel_regularizer=l2(0.00095))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = LeakyReLU(negative_slope=0.1)(x)\n",
    "x = Dropout(0.2)(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88445203-bd37-4365-b5a9-f6a48199ac8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "structured_input = Input(shape=(structured_data_scaled.shape[1],), name='structured_input')\n",
    "y = Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(0.00095))(structured_input)\n",
    "y = BatchNormalization()(y)\n",
    "y = LeakyReLU(negative_slope=0.1)(y)\n",
    "y = Dropout(0.2)(y)\n",
    "\n",
    "y = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(0.00095))(y)\n",
    "y = BatchNormalization()(y)\n",
    "y = LeakyReLU(negative_slope=0.1)(y)\n",
    "y = Dropout(0.2)(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "33daa643-4d32-4701-9e2d-5ef2f72c53da",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = Concatenate()([x, y])\n",
    "\n",
    "z = Dense(128, kernel_initializer='he_normal', kernel_regularizer=l2(0.00095))(combined)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU(negative_slope=0.1)(z)\n",
    "z = Dropout(0.2)(z)\n",
    "\n",
    "z = Dense(64, kernel_initializer='he_normal', kernel_regularizer=l2(0.00095))(z)\n",
    "z = BatchNormalization()(z)\n",
    "z = LeakyReLU(negative_slope=0.1)(z)\n",
    "z = Dropout(0.2)(z)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "59d21550-e6a1-4d6c-8758-accc3b86f51b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output 1: Condition (Binary Classification)\n",
    "condition_output = Dense(1, activation='sigmoid', name='condition_output')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19e5f437-4d2d-429d-bc38-2da646333e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output 2: Amount (Regression)\n",
    "amount_output = Dense(1, activation='linear', name='amount_output')(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a5bcfcf1-22bc-4109-b38d-e96410d861ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Model\n",
    "model = Model(inputs=[image_input, structured_input], outputs=[condition_output, amount_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ca9b532b-8131-4cf9-b4fc-11d27ecc999b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Model\n",
    "model.compile(optimizer=Adam(learning_rate=0.00095),\n",
    "              loss={'condition_output': 'binary_crossentropy', 'amount_output':tf.keras.losses.Huber()},\n",
    "              metrics={'condition_output': 'accuracy', 'amount_output': 'mse'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99582ed9-145d-415a-a758-48d6ff12284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#callback\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-6)\n",
    "checkpoint = ModelCheckpoint(r'C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras', monitor='val_loss', save_best_only=True, mode='min', verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82412ff1-0914-41b3-b866-e1a7054aabbe",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a540b812-e4e9-4a06-adfd-699e5b1df439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                  </span>┃<span style=\"font-weight: bold\"> Output Shape              </span>┃<span style=\"font-weight: bold\">         Param # </span>┃<span style=\"font-weight: bold\"> Connected to               </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ structured_input (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,088</span> │ image_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ structured_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]                │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],           │\n",
       "│                               │                           │                 │ dropout_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,088</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │ dense_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_5         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │ dense_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]              │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LeakyReLU</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ batch_normalization_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ leaky_re_lu_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ condition_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ amount_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                 │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to              \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│ image_input (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ structured_input (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ -                          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │       \u001b[38;5;34m1,049,088\u001b[0m │ image_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │           \u001b[38;5;34m2,048\u001b[0m │ structured_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │           \u001b[38;5;34m2,048\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]                │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_2         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu (\u001b[38;5;33mLeakyReLU\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_2 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │         \u001b[38;5;34m131,328\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_1         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │           \u001b[38;5;34m1,024\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_3         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_1 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_3 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m320\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],           │\n",
       "│                               │                           │                 │ dropout_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │          \u001b[38;5;34m41,088\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_4         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │             \u001b[38;5;34m512\u001b[0m │ dense_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_4 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │           \u001b[38;5;34m8,256\u001b[0m │ dropout_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ batch_normalization_5         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │             \u001b[38;5;34m256\u001b[0m │ dense_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]              │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)          │                           │                 │                            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ leaky_re_lu_5 (\u001b[38;5;33mLeakyReLU\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ batch_normalization_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │ leaky_re_lu_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ condition_output (\u001b[38;5;33mDense\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "├───────────────────────────────┼───────────────────────────┼─────────────────┼────────────────────────────┤\n",
       "│ amount_output (\u001b[38;5;33mDense\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                 │              \u001b[38;5;34m65\u001b[0m │ dropout_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
       "└───────────────────────────────┴───────────────────────────┴─────────────────┴────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,729,800</span> (14.23 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m3,729,800\u001b[0m (14.23 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,242,498</span> (4.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,242,498\u001b[0m (4.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,304</span> (9.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,304\u001b[0m (9.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,484,998</span> (9.48 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m2,484,998\u001b[0m (9.48 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d276e33-0d18-4398-9fef-4a2b714d8234",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import mlflow\n",
    "import mlflow.tensorflow\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d8876f-73d3-416d-a16a-338184012a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from mlflow.models.signature import ModelSignature\n",
    "# from mlflow.types import Schema, ColSpec\n",
    "\n",
    "# # Define the input and output schema explicitly\n",
    "# input_schema = Schema([\n",
    "#     ColSpec(type=\"array\", type=\"float32\", shape=(None, image_features.shape[1])),\n",
    "#     ColSpec(type=\"array\", type=\"float32\", shape=(None, structured_data_scaled.shape[1]))\n",
    "# ])\n",
    "\n",
    "# output_schema = Schema([\n",
    "#     ColSpec(type=\"array\", dtype=\"float32\", shape=(None, 1)),  # For condition_output\n",
    "#     ColSpec(type=\"array\", dtype=\"float32\", shape=(None, 1))   # For amount_output\n",
    "# ])\n",
    "\n",
    "# # Create ModelSignature object\n",
    "# signature = ModelSignature(inputs=input_schema, outputs=output_schema)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9bfc4247-b21f-4a97-9b94-cf5724d09378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a unique model filename using the current timestamp\n",
    "timestamp = int(time.time())\n",
    "model_path = f'C:/Users/varsh/OneDrive/Desktop/notebook/Fast_Furious_Insured/api/models/model_{timestamp}.keras'  # Unique filename using timestamp\n",
    "\n",
    "# Start a new MLflow run to track the model and metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d7ff2ea8-da71-465d-834c-005c673a2ddc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - amount_output_loss: 0.5631 - amount_output_mse: 1.6996 - condition_output_accuracy: 0.5046 - condition_output_loss: 0.7817 - loss: 3.1993\n",
      "Epoch 1: val_loss improved from inf to 2.31321, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - amount_output_loss: 0.5615 - amount_output_mse: 1.6929 - condition_output_accuracy: 0.5072 - condition_output_loss: 0.7790 - loss: 3.1924 - val_amount_output_loss: 0.1594 - val_amount_output_mse: 0.3709 - val_condition_output_accuracy: 0.5458 - val_condition_output_loss: 0.6584 - val_loss: 2.3132 - learning_rate: 9.5000e-04\n",
      "Epoch 2/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.2954 - amount_output_mse: 0.6842 - condition_output_accuracy: 0.9339 - condition_output_loss: 0.2663 - loss: 2.0256\n",
      "Epoch 2: val_loss improved from 2.31321 to 1.75909, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - amount_output_loss: 0.2954 - amount_output_mse: 0.6842 - condition_output_accuracy: 0.9342 - condition_output_loss: 0.2656 - loss: 2.0245 - val_amount_output_loss: 0.1621 - val_amount_output_mse: 0.4463 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.2031 - val_loss: 1.7591 - learning_rate: 9.5000e-04\n",
      "Epoch 3/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - amount_output_loss: 0.2643 - amount_output_mse: 0.6200 - condition_output_accuracy: 0.9891 - condition_output_loss: 0.1178 - loss: 1.7515\n",
      "Epoch 3: val_loss improved from 1.75909 to 1.54647, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - amount_output_loss: 0.2642 - amount_output_mse: 0.6197 - condition_output_accuracy: 0.9891 - condition_output_loss: 0.1177 - loss: 1.7511 - val_amount_output_loss: 0.1574 - val_amount_output_mse: 0.3864 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0775 - val_loss: 1.5465 - learning_rate: 9.5000e-04\n",
      "Epoch 4/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - amount_output_loss: 0.2575 - amount_output_mse: 0.6003 - condition_output_accuracy: 0.9872 - condition_output_loss: 0.0921 - loss: 1.6389\n",
      "Epoch 4: val_loss improved from 1.54647 to 1.41153, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - amount_output_loss: 0.2571 - amount_output_mse: 0.5996 - condition_output_accuracy: 0.9873 - condition_output_loss: 0.0917 - loss: 1.6376 - val_amount_output_loss: 0.1508 - val_amount_output_mse: 0.3664 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0265 - val_loss: 1.4115 - learning_rate: 9.5000e-04\n",
      "Epoch 5/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - amount_output_loss: 0.2303 - amount_output_mse: 0.5209 - condition_output_accuracy: 0.9955 - condition_output_loss: 0.0564 - loss: 1.5004\n",
      "Epoch 5: val_loss improved from 1.41153 to 1.29974, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - amount_output_loss: 0.2301 - amount_output_mse: 0.5204 - condition_output_accuracy: 0.9954 - condition_output_loss: 0.0564 - loss: 1.5000 - val_amount_output_loss: 0.1167 - val_amount_output_mse: 0.2489 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0215 - val_loss: 1.2997 - learning_rate: 9.5000e-04\n",
      "Epoch 6/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.2248 - amount_output_mse: 0.5152 - condition_output_accuracy: 0.9814 - condition_output_loss: 0.0697 - loss: 1.4382\n",
      "Epoch 6: val_loss improved from 1.29974 to 1.28890, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.2245 - amount_output_mse: 0.5145 - condition_output_accuracy: 0.9816 - condition_output_loss: 0.0695 - loss: 1.4375 - val_amount_output_loss: 0.1780 - val_amount_output_mse: 0.4540 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0148 - val_loss: 1.2889 - learning_rate: 9.5000e-04\n",
      "Epoch 7/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1935 - amount_output_mse: 0.4318 - condition_output_accuracy: 0.9974 - condition_output_loss: 0.0364 - loss: 1.3068\n",
      "Epoch 7: val_loss improved from 1.28890 to 1.17684, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - amount_output_loss: 0.1935 - amount_output_mse: 0.4319 - condition_output_accuracy: 0.9974 - condition_output_loss: 0.0364 - loss: 1.3065 - val_amount_output_loss: 0.1371 - val_amount_output_mse: 0.3113 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0099 - val_loss: 1.1768 - learning_rate: 9.5000e-04\n",
      "Epoch 8/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1931 - amount_output_mse: 0.4310 - condition_output_accuracy: 0.9945 - condition_output_loss: 0.0328 - loss: 1.2384\n",
      "Epoch 8: val_loss improved from 1.17684 to 1.08173, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1931 - amount_output_mse: 0.4308 - condition_output_accuracy: 0.9945 - condition_output_loss: 0.0328 - loss: 1.2379 - val_amount_output_loss: 0.1084 - val_amount_output_mse: 0.2246 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0077 - val_loss: 1.0817 - learning_rate: 9.5000e-04\n",
      "Epoch 9/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1681 - amount_output_mse: 0.3662 - condition_output_accuracy: 0.9921 - condition_output_loss: 0.0332 - loss: 1.1518\n",
      "Epoch 9: val_loss improved from 1.08173 to 1.02209, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1683 - amount_output_mse: 0.3668 - condition_output_accuracy: 0.9922 - condition_output_loss: 0.0332 - loss: 1.1515 - val_amount_output_loss: 0.1104 - val_amount_output_mse: 0.2277 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0051 - val_loss: 1.0221 - learning_rate: 9.5000e-04\n",
      "Epoch 10/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1694 - amount_output_mse: 0.3731 - condition_output_accuracy: 0.9974 - condition_output_loss: 0.0244 - loss: 1.0850\n",
      "Epoch 10: val_loss improved from 1.02209 to 1.00681, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1695 - amount_output_mse: 0.3732 - condition_output_accuracy: 0.9974 - condition_output_loss: 0.0243 - loss: 1.0848 - val_amount_output_loss: 0.1521 - val_amount_output_mse: 0.3550 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0045 - val_loss: 1.0068 - learning_rate: 9.5000e-04\n",
      "Epoch 11/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - amount_output_loss: 0.1608 - amount_output_mse: 0.3489 - condition_output_accuracy: 0.9945 - condition_output_loss: 0.0336 - loss: 1.0291\n",
      "Epoch 11: val_loss improved from 1.00681 to 0.92341, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - amount_output_loss: 0.1607 - amount_output_mse: 0.3486 - condition_output_accuracy: 0.9945 - condition_output_loss: 0.0335 - loss: 1.0284 - val_amount_output_loss: 0.1203 - val_amount_output_mse: 0.2529 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0090 - val_loss: 0.9234 - learning_rate: 9.5000e-04\n",
      "Epoch 12/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1749 - amount_output_mse: 0.3905 - condition_output_accuracy: 0.9976 - condition_output_loss: 0.0228 - loss: 0.9789\n",
      "Epoch 12: val_loss improved from 0.92341 to 0.84481, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - amount_output_loss: 0.1743 - amount_output_mse: 0.3890 - condition_output_accuracy: 0.9976 - condition_output_loss: 0.0227 - loss: 0.9779 - val_amount_output_loss: 0.0980 - val_amount_output_mse: 0.1987 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0043 - val_loss: 0.8448 - learning_rate: 9.5000e-04\n",
      "Epoch 13/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1353 - amount_output_mse: 0.2845 - condition_output_accuracy: 0.9980 - condition_output_loss: 0.0177 - loss: 0.8832\n",
      "Epoch 13: val_loss improved from 0.84481 to 0.79159, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - amount_output_loss: 0.1357 - amount_output_mse: 0.2853 - condition_output_accuracy: 0.9980 - condition_output_loss: 0.0176 - loss: 0.8831 - val_amount_output_loss: 0.0968 - val_amount_output_mse: 0.1936 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0027 - val_loss: 0.7916 - learning_rate: 9.5000e-04\n",
      "Epoch 14/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1494 - amount_output_mse: 0.3259 - condition_output_accuracy: 0.9984 - condition_output_loss: 0.0158 - loss: 0.8466\n",
      "Epoch 14: val_loss improved from 0.79159 to 0.73264, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1490 - amount_output_mse: 0.3248 - condition_output_accuracy: 0.9984 - condition_output_loss: 0.0158 - loss: 0.8459 - val_amount_output_loss: 0.0833 - val_amount_output_mse: 0.1682 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0031 - val_loss: 0.7326 - learning_rate: 9.5000e-04\n",
      "Epoch 15/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1323 - amount_output_mse: 0.2775 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0103 - loss: 0.7783\n",
      "Epoch 15: val_loss improved from 0.73264 to 0.70788, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - amount_output_loss: 0.1323 - amount_output_mse: 0.2776 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0103 - loss: 0.7780 - val_amount_output_loss: 0.1019 - val_amount_output_mse: 0.2081 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0033 - val_loss: 0.7079 - learning_rate: 9.5000e-04\n",
      "Epoch 16/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - amount_output_loss: 0.1407 - amount_output_mse: 0.3001 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0090 - loss: 0.7414\n",
      "Epoch 16: val_loss improved from 0.70788 to 0.67743, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - amount_output_loss: 0.1408 - amount_output_mse: 0.3003 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0090 - loss: 0.7414 - val_amount_output_loss: 0.1159 - val_amount_output_mse: 0.2351 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0015 - val_loss: 0.6774 - learning_rate: 9.5000e-04\n",
      "Epoch 17/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1249 - amount_output_mse: 0.2635 - condition_output_accuracy: 0.9972 - condition_output_loss: 0.0142 - loss: 0.6906\n",
      "Epoch 17: val_loss improved from 0.67743 to 0.66395, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - amount_output_loss: 0.1256 - amount_output_mse: 0.2653 - condition_output_accuracy: 0.9972 - condition_output_loss: 0.0143 - loss: 0.6912 - val_amount_output_loss: 0.1387 - val_amount_output_mse: 0.2865 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0014 - val_loss: 0.6640 - learning_rate: 9.5000e-04\n",
      "Epoch 18/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1347 - amount_output_mse: 0.2819 - condition_output_accuracy: 0.9986 - condition_output_loss: 0.0133 - loss: 0.6643\n",
      "Epoch 18: val_loss improved from 0.66395 to 0.58911, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1346 - amount_output_mse: 0.2816 - condition_output_accuracy: 0.9986 - condition_output_loss: 0.0133 - loss: 0.6638 - val_amount_output_loss: 0.0989 - val_amount_output_mse: 0.1970 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0026 - val_loss: 0.5891 - learning_rate: 9.5000e-04\n",
      "Epoch 19/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1256 - amount_output_mse: 0.2621 - condition_output_accuracy: 0.9986 - condition_output_loss: 0.0114 - loss: 0.6176\n",
      "Epoch 19: val_loss improved from 0.58911 to 0.55880, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - amount_output_loss: 0.1261 - amount_output_mse: 0.2633 - condition_output_accuracy: 0.9985 - condition_output_loss: 0.0116 - loss: 0.6179 - val_amount_output_loss: 0.1021 - val_amount_output_mse: 0.2098 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0015 - val_loss: 0.5588 - learning_rate: 9.5000e-04\n",
      "Epoch 20/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1385 - amount_output_mse: 0.2928 - condition_output_accuracy: 0.9977 - condition_output_loss: 0.0114 - loss: 0.5977\n",
      "Epoch 20: val_loss improved from 0.55880 to 0.51761, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - amount_output_loss: 0.1381 - amount_output_mse: 0.2919 - condition_output_accuracy: 0.9977 - condition_output_loss: 0.0114 - loss: 0.5971 - val_amount_output_loss: 0.0918 - val_amount_output_mse: 0.1877 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 6.7270e-04 - val_loss: 0.5176 - learning_rate: 9.5000e-04\n",
      "Epoch 21/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - amount_output_loss: 0.1414 - amount_output_mse: 0.2971 - condition_output_accuracy: 0.9953 - condition_output_loss: 0.0179 - loss: 0.5777\n",
      "Epoch 21: val_loss did not improve from 0.51761\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 39ms/step - amount_output_loss: 0.1413 - amount_output_mse: 0.2967 - condition_output_accuracy: 0.9954 - condition_output_loss: 0.0177 - loss: 0.5771 - val_amount_output_loss: 0.1274 - val_amount_output_mse: 0.2466 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0011 - val_loss: 0.5209 - learning_rate: 9.5000e-04\n",
      "Epoch 22/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1353 - amount_output_mse: 0.2846 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0119 - loss: 0.5376\n",
      "Epoch 22: val_loss improved from 0.51761 to 0.45467, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - amount_output_loss: 0.1353 - amount_output_mse: 0.2848 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0118 - loss: 0.5373 - val_amount_output_loss: 0.0869 - val_amount_output_mse: 0.1710 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 3.4029e-04 - val_loss: 0.4547 - learning_rate: 9.5000e-04\n",
      "Epoch 23/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1242 - amount_output_mse: 0.2603 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0058 - loss: 0.4935\n",
      "Epoch 23: val_loss did not improve from 0.45467\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - amount_output_loss: 0.1240 - amount_output_mse: 0.2598 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0059 - loss: 0.4931 - val_amount_output_loss: 0.1381 - val_amount_output_mse: 0.2897 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 9.3026e-04 - val_loss: 0.4832 - learning_rate: 9.5000e-04\n",
      "Epoch 24/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1331 - amount_output_mse: 0.2779 - condition_output_accuracy: 0.9977 - condition_output_loss: 0.0100 - loss: 0.4814\n",
      "Epoch 24: val_loss did not improve from 0.45467\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - amount_output_loss: 0.1330 - amount_output_mse: 0.2778 - condition_output_accuracy: 0.9977 - condition_output_loss: 0.0100 - loss: 0.4812 - val_amount_output_loss: 0.1519 - val_amount_output_mse: 0.2988 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0012 - val_loss: 0.4719 - learning_rate: 9.5000e-04\n",
      "Epoch 25/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1125 - amount_output_mse: 0.2298 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0041 - loss: 0.4329\n",
      "Epoch 25: val_loss improved from 0.45467 to 0.41808, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1127 - amount_output_mse: 0.2302 - condition_output_accuracy: 0.9999 - condition_output_loss: 0.0041 - loss: 0.4329 - val_amount_output_loss: 0.1171 - val_amount_output_mse: 0.2440 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0011 - val_loss: 0.4181 - learning_rate: 9.5000e-04\n",
      "Epoch 26/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - amount_output_loss: 0.1098 - amount_output_mse: 0.2288 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0050 - loss: 0.4086\n",
      "Epoch 26: val_loss did not improve from 0.41808\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1099 - amount_output_mse: 0.2289 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0050 - loss: 0.4085 - val_amount_output_loss: 0.2213 - val_amount_output_mse: 0.4286 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0017 - val_loss: 0.4925 - learning_rate: 9.5000e-04\n",
      "Epoch 27/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1160 - amount_output_mse: 0.2389 - condition_output_accuracy: 0.9992 - condition_output_loss: 0.0055 - loss: 0.3953\n",
      "Epoch 27: val_loss improved from 0.41808 to 0.36624, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 42ms/step - amount_output_loss: 0.1162 - amount_output_mse: 0.2392 - condition_output_accuracy: 0.9992 - condition_output_loss: 0.0055 - loss: 0.3954 - val_amount_output_loss: 0.1055 - val_amount_output_mse: 0.2151 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 5.5682e-04 - val_loss: 0.3662 - learning_rate: 9.5000e-04\n",
      "Epoch 28/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - amount_output_loss: 0.1186 - amount_output_mse: 0.2655 - condition_output_accuracy: 0.9972 - condition_output_loss: 0.0324 - loss: 0.4067\n",
      "Epoch 28: val_loss improved from 0.36624 to 0.33392, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - amount_output_loss: 0.1186 - amount_output_mse: 0.2653 - condition_output_accuracy: 0.9972 - condition_output_loss: 0.0321 - loss: 0.4064 - val_amount_output_loss: 0.0930 - val_amount_output_mse: 0.1833 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 5.9146e-04 - val_loss: 0.3339 - learning_rate: 9.5000e-04\n",
      "Epoch 29/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - amount_output_loss: 0.1291 - amount_output_mse: 0.2760 - condition_output_accuracy: 0.9986 - condition_output_loss: 0.0081 - loss: 0.3759\n",
      "Epoch 29: val_loss did not improve from 0.33392\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - amount_output_loss: 0.1289 - amount_output_mse: 0.2757 - condition_output_accuracy: 0.9986 - condition_output_loss: 0.0081 - loss: 0.3757 - val_amount_output_loss: 0.1724 - val_amount_output_mse: 0.3632 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 6.8280e-04 - val_loss: 0.4042 - learning_rate: 9.5000e-04\n",
      "Epoch 30/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - amount_output_loss: 0.1339 - amount_output_mse: 0.2856 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0066 - loss: 0.3653\n",
      "Epoch 30: val_loss improved from 0.33392 to 0.29806, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - amount_output_loss: 0.1338 - amount_output_mse: 0.2853 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0066 - loss: 0.3651 - val_amount_output_loss: 0.0874 - val_amount_output_mse: 0.1704 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.8645e-04 - val_loss: 0.2981 - learning_rate: 9.5000e-04\n",
      "Epoch 31/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - amount_output_loss: 0.1158 - amount_output_mse: 0.2419 - condition_output_accuracy: 0.9997 - condition_output_loss: 0.0039 - loss: 0.3296\n",
      "Epoch 31: val_loss did not improve from 0.29806\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - amount_output_loss: 0.1163 - amount_output_mse: 0.2430 - condition_output_accuracy: 0.9997 - condition_output_loss: 0.0039 - loss: 0.3300 - val_amount_output_loss: 0.2233 - val_amount_output_mse: 0.4353 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 0.0011 - val_loss: 0.4184 - learning_rate: 9.5000e-04\n",
      "Epoch 32/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1125 - amount_output_mse: 0.2333 - condition_output_accuracy: 0.9998 - condition_output_loss: 0.0027 - loss: 0.3140    \n",
      "Epoch 32: val_loss improved from 0.29806 to 0.27182, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1125 - amount_output_mse: 0.2336 - condition_output_accuracy: 0.9998 - condition_output_loss: 0.0027 - loss: 0.3140 - val_amount_output_loss: 0.0811 - val_amount_output_mse: 0.1648 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 4.5119e-04 - val_loss: 0.2718 - learning_rate: 9.5000e-04\n",
      "Epoch 33/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1203 - amount_output_mse: 0.2497 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0050 - loss: 0.3131\n",
      "Epoch 33: val_loss did not improve from 0.27182\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.1201 - amount_output_mse: 0.2493 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0050 - loss: 0.3128 - val_amount_output_loss: 0.2015 - val_amount_output_mse: 0.4038 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 4.4715e-04 - val_loss: 0.3746 - learning_rate: 9.5000e-04\n",
      "Epoch 34/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1193 - amount_output_mse: 0.2514 - condition_output_accuracy: 0.9982 - condition_output_loss: 0.0058 - loss: 0.3022\n",
      "Epoch 34: val_loss did not improve from 0.27182\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - amount_output_loss: 0.1194 - amount_output_mse: 0.2516 - condition_output_accuracy: 0.9982 - condition_output_loss: 0.0058 - loss: 0.3022 - val_amount_output_loss: 0.1183 - val_amount_output_mse: 0.2464 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 9.7670e-05 - val_loss: 0.2890 - learning_rate: 9.5000e-04\n",
      "Epoch 35/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1262 - amount_output_mse: 0.2622 - condition_output_accuracy: 0.9973 - condition_output_loss: 0.0072 - loss: 0.3006\n",
      "Epoch 35: val_loss did not improve from 0.27182\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - amount_output_loss: 0.1263 - amount_output_mse: 0.2626 - condition_output_accuracy: 0.9973 - condition_output_loss: 0.0072 - loss: 0.3007 - val_amount_output_loss: 0.1692 - val_amount_output_mse: 0.3596 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 2.4793e-04 - val_loss: 0.3308 - learning_rate: 9.5000e-04\n",
      "Epoch 36/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - amount_output_loss: 0.0896 - amount_output_mse: 0.1837 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0019 - loss: 0.2505\n",
      "Epoch 36: val_loss improved from 0.27182 to 0.26689, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - amount_output_loss: 0.0901 - amount_output_mse: 0.1846 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0020 - loss: 0.2509 - val_amount_output_loss: 0.1176 - val_amount_output_mse: 0.2266 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.6478e-04 - val_loss: 0.2669 - learning_rate: 4.7500e-04\n",
      "Epoch 37/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1008 - amount_output_mse: 0.2045 - condition_output_accuracy: 0.9999 - condition_output_loss: 0.0021 - loss: 0.2559    \n",
      "Epoch 37: val_loss improved from 0.26689 to 0.24527, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - amount_output_loss: 0.1010 - amount_output_mse: 0.2051 - condition_output_accuracy: 0.9998 - condition_output_loss: 0.0022 - loss: 0.2562 - val_amount_output_loss: 0.0965 - val_amount_output_mse: 0.1969 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.8998e-04 - val_loss: 0.2453 - learning_rate: 4.7500e-04\n",
      "Epoch 38/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.1021 - amount_output_mse: 0.2098 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0020 - loss: 0.2517    \n",
      "Epoch 38: val_loss improved from 0.24527 to 0.23599, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1024 - amount_output_mse: 0.2105 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0021 - loss: 0.2519 - val_amount_output_loss: 0.0932 - val_amount_output_mse: 0.1889 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.9623e-04 - val_loss: 0.2360 - learning_rate: 4.7500e-04\n",
      "Epoch 39/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - amount_output_loss: 0.1174 - amount_output_mse: 0.2467 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0032 - loss: 0.2628\n",
      "Epoch 39: val_loss did not improve from 0.23599\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.1169 - amount_output_mse: 0.2457 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0032 - loss: 0.2623 - val_amount_output_loss: 0.1527 - val_amount_output_mse: 0.3228 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.7047e-04 - val_loss: 0.2919 - learning_rate: 4.7500e-04\n",
      "Epoch 40/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1062 - amount_output_mse: 0.2196 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0018 - loss: 0.2452\n",
      "Epoch 40: val_loss did not improve from 0.23599\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 36ms/step - amount_output_loss: 0.1062 - amount_output_mse: 0.2197 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0018 - loss: 0.2452 - val_amount_output_loss: 0.1059 - val_amount_output_mse: 0.2189 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.6780e-04 - val_loss: 0.2398 - learning_rate: 4.7500e-04\n",
      "Epoch 41/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1006 - amount_output_mse: 0.2070 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0022 - loss: 0.2350\n",
      "Epoch 41: val_loss improved from 0.23599 to 0.22395, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.1006 - amount_output_mse: 0.2070 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0022 - loss: 0.2350 - val_amount_output_loss: 0.0994 - val_amount_output_mse: 0.1911 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 3.0982e-04 - val_loss: 0.2240 - learning_rate: 4.7500e-04\n",
      "Epoch 42/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0977 - amount_output_mse: 0.2023 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0015 - loss: 0.2269\n",
      "Epoch 42: val_loss did not improve from 0.22395\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.0979 - amount_output_mse: 0.2025 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0015 - loss: 0.2271 - val_amount_output_loss: 0.1306 - val_amount_output_mse: 0.2725 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.1242e-04 - val_loss: 0.2564 - learning_rate: 4.7500e-04\n",
      "Epoch 43/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0911 - amount_output_mse: 0.1886 - condition_output_accuracy: 0.9991 - condition_output_loss: 0.0033 - loss: 0.2181\n",
      "Epoch 43: val_loss did not improve from 0.22395\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.0914 - amount_output_mse: 0.1893 - condition_output_accuracy: 0.9991 - condition_output_loss: 0.0033 - loss: 0.2184 - val_amount_output_loss: 0.1288 - val_amount_output_mse: 0.2670 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.0916e-04 - val_loss: 0.2505 - learning_rate: 4.7500e-04\n",
      "Epoch 44/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.1026 - amount_output_mse: 0.2101 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0019 - loss: 0.2249\n",
      "Epoch 44: val_loss did not improve from 0.22395\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - amount_output_loss: 0.1029 - amount_output_mse: 0.2107 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0020 - loss: 0.2252 - val_amount_output_loss: 0.1223 - val_amount_output_mse: 0.2558 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 9.6121e-05 - val_loss: 0.2417 - learning_rate: 4.7500e-04\n",
      "Epoch 45/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - amount_output_loss: 0.0899 - amount_output_mse: 0.1887 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0016 - loss: 0.2087    \n",
      "Epoch 45: val_loss improved from 0.22395 to 0.21401, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.0902 - amount_output_mse: 0.1892 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0016 - loss: 0.2089 - val_amount_output_loss: 0.0983 - val_amount_output_mse: 0.2027 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.2590e-04 - val_loss: 0.2140 - learning_rate: 2.3750e-04\n",
      "Epoch 46/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0852 - amount_output_mse: 0.1728 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.2009    \n",
      "Epoch 46: val_loss improved from 0.21401 to 0.20210, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 44ms/step - amount_output_loss: 0.0852 - amount_output_mse: 0.1728 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.2009 - val_amount_output_loss: 0.0906 - val_amount_output_mse: 0.1828 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.5539e-04 - val_loss: 0.2021 - learning_rate: 2.3750e-04\n",
      "Epoch 47/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0877 - amount_output_mse: 0.1817 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0027 - loss: 0.2022    \n",
      "Epoch 47: val_loss did not improve from 0.20210\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 37ms/step - amount_output_loss: 0.0878 - amount_output_mse: 0.1820 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0027 - loss: 0.2023 - val_amount_output_loss: 0.1352 - val_amount_output_mse: 0.2828 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 8.3872e-05 - val_loss: 0.2462 - learning_rate: 2.3750e-04\n",
      "Epoch 48/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0865 - amount_output_mse: 0.1747 - condition_output_accuracy: 1.0000 - condition_output_loss: 9.6684e-04 - loss: 0.1970\n",
      "Epoch 48: val_loss did not improve from 0.20210\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.0867 - amount_output_mse: 0.1751 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0010 - loss: 0.1972 - val_amount_output_loss: 0.0964 - val_amount_output_mse: 0.1967 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.2371e-04 - val_loss: 0.2041 - learning_rate: 2.3750e-04\n",
      "Epoch 49/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - amount_output_loss: 0.0950 - amount_output_mse: 0.1951 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0015 - loss: 0.2039     \n",
      "Epoch 49: val_loss did not improve from 0.20210\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 40ms/step - amount_output_loss: 0.0949 - amount_output_mse: 0.1948 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0015 - loss: 0.2038 - val_amount_output_loss: 0.1119 - val_amount_output_mse: 0.2315 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.2364e-04 - val_loss: 0.2187 - learning_rate: 2.3750e-04\n",
      "Epoch 50/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - amount_output_loss: 0.0840 - amount_output_mse: 0.1702 - condition_output_accuracy: 0.9997 - condition_output_loss: 0.0014 - loss: 0.1909    \n",
      "Epoch 50: val_loss did not improve from 0.20210\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - amount_output_loss: 0.0840 - amount_output_mse: 0.1702 - condition_output_accuracy: 0.9997 - condition_output_loss: 0.0014 - loss: 0.1909 - val_amount_output_loss: 0.1141 - val_amount_output_mse: 0.2380 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.0947e-04 - val_loss: 0.2197 - learning_rate: 1.1875e-04\n",
      "Epoch 51/200\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - amount_output_loss: 0.1030 - amount_output_mse: 0.2103 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.2087\n",
      "Epoch 51: val_loss improved from 0.20210 to 0.18884, saving model to C:\\Users\\varsh\\OneDrive\\Desktop\\notebook\\Fast_Furious_Insured\\api\\models\\best_model.keras\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - amount_output_loss: 0.1028 - amount_output_mse: 0.2099 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.2085 - val_amount_output_loss: 0.0876 - val_amount_output_mse: 0.1730 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.6798e-04 - val_loss: 0.1888 - learning_rate: 1.1875e-04\n",
      "Epoch 52/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - amount_output_loss: 0.0780 - amount_output_mse: 0.1579 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0016 - loss: 0.1828\n",
      "Epoch 52: val_loss did not improve from 0.18884\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.0781 - amount_output_mse: 0.1582 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0017 - loss: 0.1829 - val_amount_output_loss: 0.1175 - val_amount_output_mse: 0.2445 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 8.6756e-05 - val_loss: 0.2206 - learning_rate: 1.1875e-04\n",
      "Epoch 53/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - amount_output_loss: 0.0772 - amount_output_mse: 0.1554 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.1804\n",
      "Epoch 53: val_loss did not improve from 0.18884\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 43ms/step - amount_output_loss: 0.0774 - amount_output_mse: 0.1556 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.1805 - val_amount_output_loss: 0.1069 - val_amount_output_mse: 0.2217 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 9.4727e-05 - val_loss: 0.2088 - learning_rate: 1.1875e-04\n",
      "Epoch 54/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - amount_output_loss: 0.0729 - amount_output_mse: 0.1480 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.1749    \n",
      "Epoch 54: val_loss did not improve from 0.18884\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 41ms/step - amount_output_loss: 0.0730 - amount_output_mse: 0.1482 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0013 - loss: 0.1750 - val_amount_output_loss: 0.1240 - val_amount_output_mse: 0.2584 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 9.5042e-05 - val_loss: 0.2248 - learning_rate: 1.1875e-04\n",
      "Epoch 55/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0703 - amount_output_mse: 0.1416 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0012 - loss: 0.1711\n",
      "Epoch 55: val_loss did not improve from 0.18884\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.0705 - amount_output_mse: 0.1420 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0012 - loss: 0.1713 - val_amount_output_loss: 0.1088 - val_amount_output_mse: 0.2258 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.0555e-04 - val_loss: 0.2085 - learning_rate: 5.9375e-05\n",
      "Epoch 56/200\n",
      "\u001b[1m65/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - amount_output_loss: 0.0878 - amount_output_mse: 0.1780 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0021 - loss: 0.1889\n",
      "Epoch 56: val_loss did not improve from 0.18884\n",
      "\u001b[1m66/66\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 38ms/step - amount_output_loss: 0.0878 - amount_output_mse: 0.1781 - condition_output_accuracy: 1.0000 - condition_output_loss: 0.0021 - loss: 0.1889 - val_amount_output_loss: 0.0928 - val_amount_output_mse: 0.1868 - val_condition_output_accuracy: 1.0000 - val_condition_output_loss: 1.3004e-04 - val_loss: 0.1902 - learning_rate: 5.9375e-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 13:22:01 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
      "2025/02/14 13:22:39 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trained model saved and logged in MLflow at C:/Users/varsh/OneDrive/Desktop/notebook/Fast_Furious_Insured/api/models/model_1739519356.keras\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run():\n",
    "    # Log hyperparameters\n",
    "    mlflow.log_param('learning_rate', 0.00095)\n",
    "    mlflow.log_param('epochs', 200)\n",
    "    mlflow.log_param('batch_size', 16)\n",
    "\n",
    "    # Train the model before saving/logging\n",
    "    history = model.fit(\n",
    "        [image_features, structured_data_scaled],  # Inputs\n",
    "        {'condition_output': condition_labels, 'amount_output': amount_labels},  # Outputs\n",
    "        epochs=200,\n",
    "        batch_size=16,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping, reduce_lr, checkpoint],  # Callbacks\n",
    "        verbose=1\n",
    "    )\n",
    "\n",
    "    # Log final training metrics (avoid KeyErrors)\n",
    "    mlflow.log_metric('condition_output_accuracy', history.history.get('condition_output_accuracy', [None])[-1])\n",
    "    mlflow.log_metric('amount_output_mse', history.history.get('amount_output_mse', [None])[-1])\n",
    "    \n",
    "    # Optionally log validation metrics\n",
    "    mlflow.log_metric('val_condition_output_accuracy', history.history.get('val_condition_output_accuracy', [None])[-1])\n",
    "    mlflow.log_metric('val_amount_output_mse', history.history.get('val_amount_output_mse', [None])[-1])\n",
    "\n",
    "    # Save and log trained model with a unique filename\n",
    "    model.save(model_path)\n",
    "    mlflow.tensorflow.log_model(model, artifact_path=\"model\")  # Log trained model\n",
    "\n",
    "    print(f\"Trained model saved and logged in MLflow at {model_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d9d263a6-f6e2-46b0-a5c7-08d0b017e36b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and validation loss\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e7fc882d-9a55-4812-a282-cd79a97ae49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Training and Validation Metrics:\n",
      "\n",
      "Training Metrics:\n",
      "amount_output_loss: 0.0893\n",
      "amount_output_mse: 0.1804\n",
      "condition_output_accuracy: 1.0000\n",
      "condition_output_loss: 0.0017\n",
      "loss: 0.1895\n",
      "learning_rate: 0.0001\n",
      "\n",
      "Validation Metrics:\n",
      "val_amount_output_loss: 0.0928\n",
      "val_amount_output_mse: 0.1868\n",
      "val_condition_output_accuracy: 1.0000\n",
      "val_condition_output_loss: 0.0001\n",
      "val_loss: 0.1902\n"
     ]
    }
   ],
   "source": [
    "# Print the final training and validation metrics and losses\n",
    "print(\"Final Training and Validation Metrics:\")\n",
    "\n",
    "# Print the final training metrics\n",
    "print(\"\\nTraining Metrics:\")\n",
    "for metric, values in history.history.items():\n",
    "    if 'val_' not in metric:  # Training metrics do not contain 'val_'\n",
    "        print(f\"{metric}: {values[-1]:.4f}\")  # Print the last value for each training metric\n",
    "\n",
    "# Print the final validation metrics\n",
    "print(\"\\nValidation Metrics:\")\n",
    "for metric, values in history.history.items():\n",
    "    if 'val_' in metric:  # Validation metrics contain 'val_'\n",
    "        print(f\"{metric}: {values[-1]:.4f}\")  # Print the last value for each validation metric\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350a0d40-f7af-4e2a-a378-6a9c6e546859",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f77829e-df9a-45c6-96a9-c59d0b5a924b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3.11"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
